# Desafio T√©cnico FADESP ‚Äî Engenharia e An√°lise de Dados

Este projeto foi desenvolvido como parte do processo seletivo para a vaga de Analista de BI na FADESP.  
O objetivo √© realizar uma an√°lise explorat√≥ria completa relacionando dados do **Censo da Educa√ß√£o Superior (INEP)** com os **Bolsistas de Pesquisa do CNPq**, identificando padr√µes e gerando insights pr√°ticos para tomada de decis√£o.

---

## üìÅ **Estrutura do Reposit√≥rio**

- **/data/** ‚Üí Cont√©m os arquivos de entrada:
  - `MICRODADOS_CADASTRO_CURSOS_2023.CSV`
  - `MICRODADOS_ED_SUP_IES_2023.CSV`
  - `Relatorio_de_dados_abertos_CNPq (1¬∫ SEM 2023)(snICJ).xlsx`
- **/notebooks/** ‚Üí Notebook com toda a an√°lise, gr√°ficos interativos e coment√°rios.
- **/scripts/** ‚Üí Scripts Python para carga, limpeza e organiza√ß√£o dos dados.
- **app.py** ‚Üí Aplica√ß√£o interativa com Streamlit.
- **requirements.txt** ‚Üí Lista de bibliotecas necess√°rias.

---

##  **Pr√©-Requisitos**
>  **Aten√ß√£o:**  
##  Pr√©-requisitos
1. Baixe o arquivo ZIP: [Link para o download](https://nuvem.cnpq.br/index.php/s/fLrSsC9wfeL8HWZ/download)
2. Extraia o conte√∫do na pasta `data/` do projeto



##  **Como Executar o Projeto**

1Ô∏è **Clone o reposit√≥rio**

git clone https://github.com/SEU_USUARIO/desafio_tecnico_fadesp.git
cd desafio_tecnico_fadesp

python -m venv venv
Ative:

Windows: venv\Scripts\activate

Linux/Mac: source venv/bin/activate

 Instale as depend√™ncias

pip install -r requirements.txt
 Execute o notebook

Abra o arquivo notebooks/analise_exploratoria.ipynb e rode c√©lula por c√©lula.

 Ou execute a aplica√ß√£o Streamlit

## geralmente leva alguns segundos para abrir tudo

streamlit run app.py
 Principais Funcionalidades
Pr√©-visualiza√ß√£o de dados limpos.

Gr√°ficos interativos (Plotly) com an√°lise por UF, categoria administrativa e organiza√ß√£o acad√™mica.

Heatmap para identificar distribui√ß√µes relevantes.

Compara√ß√£o cruzada entre cursos cadastrados e n√∫mero de bolsistas do CNPq.

C√≥digo robusto para lidar com colunas inconsistentes.

## ETL e Banco de Dados

Este projeto usa **PostgreSQL** via **Docker** para armazenar os dados limpos.

- O `docker-compose.yml` sobe o container do banco.
- O script `limpeza.py` trata os dados e exporta para o PostgreSQL usando `SQLAlchemy`.
- O esquema relacional est√° definido no `db_schema.sql` para consultas normalizadas.

**Passos r√°pidos:**

# Subir o banco:
docker-compose up -d

# Criar tabelas:
psql -h localhost -U user -d fadesp_db -f db_schema.sql

# Rodar ETL:
python scripts/limpeza.py


 Observa√ß√µes Finais
N√£o esque√ßa: Os arquivos originais devem estar em /data/.

O projeto foi estruturado para ser modular, documentado e f√°cil de entender.

Para executar em outro computador, basta clonar o reposit√≥rio, instalar as depend√™ncias e colocar os arquivos na pasta certa.
